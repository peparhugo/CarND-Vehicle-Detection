{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection Pipeline\n",
    "This notebook will process a video to detect cars in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#cell block 1\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from prod_feature_extraction import *\n",
    "from prod_sliding_window import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from scipy.ndimage.measurements import label\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.models import load_model\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cell block 2\n",
    "#load classifier, scaler, and feature select\n",
    "with open('linearsvc_vehicle_classifier.pkl', 'rb') as f:\n",
    "    classifier_dict = pickle.load(f)\n",
    "\n",
    "\n",
    "clf=load_model(\"model_alt.h5\")\n",
    "X_scaler = classifier_dict[\"scaler\"]\n",
    "### TODO: Tweak these parameters and see how the results change.\n",
    "color_space = 'YUV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (24, 24) # Spatial binning dimensions\n",
    "hist_bins = 20    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "y_start_stop = [500, None] # Min and max in y to search in slide_window()\n",
    "def video_process_lines(img):\n",
    "    image = img\n",
    "    draw_image = np.copy(image)\n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    # Uncomment the following line if you extracted training\n",
    "    # data from .png images (scaled 0 to 1 by mpimg) and the\n",
    "    # image you are searching is a .jpg (scaled 0 to 255)\n",
    "    org_image=np.copy(image)\n",
    "    image = image.astype(np.float32)/255\n",
    "\n",
    "    windows = slide_window(image, x_start_stop=[image.shape[1]-360, None], y_start_stop=[380,600], \n",
    "                        xy_window=(180, 180), xy_overlap=(0.85, 0.8))\n",
    "    \n",
    "   \n",
    "    \n",
    "    #windows.extend(slide_window(image, x_start_stop=[500, 1000], y_start_stop=[380,500], \n",
    "    #                    xy_window=(60, 60), xy_overlap=(0.65, 0.6)))\n",
    "    \n",
    "    windows.extend(slide_window(image, x_start_stop=[500, None], y_start_stop=[380,520], \n",
    "                        xy_window=(80, 80), xy_overlap=(0.7, 0.7)))\n",
    "                        \n",
    "    windows.extend(slide_window(image, x_start_stop=[500, None], y_start_stop=[380,520], \n",
    "                        xy_window=(90, 90), xy_overlap=(0.60, 0.7)))\n",
    "    \n",
    "    windows.extend(slide_window(image, x_start_stop=[500, None], y_start_stop=[380,520], \n",
    "                        xy_window=(110, 110), xy_overlap=(0.50, 0.5)))\n",
    "    \n",
    "    windows.extend(slide_window(image, x_start_stop=[image.shape[1]-230, None], y_start_stop=[380,600], \n",
    "                        xy_window=(110, 110), xy_overlap=(0.80, 0.75)))\n",
    "    \n",
    "    windows.extend(slide_window(image, x_start_stop=[image.shape[1]-360, None], y_start_stop=[380,600], \n",
    "                        xy_window=(90, 90), xy_overlap=(0.80, 0.75)))\n",
    "                        \n",
    "    windows.extend(slide_window(image, x_start_stop=[image.shape[1]-150, None], y_start_stop=[380,700], \n",
    "                        xy_window=(150, 150), xy_overlap=(0.71, 0.6)))\n",
    "    \n",
    "    windows.extend(slide_window(image, x_start_stop=[400, None], y_start_stop=[380,600], \n",
    "                        xy_window=(180, 180), xy_overlap=(0.8, 0.8)))\n",
    "                        \n",
    "    windows.extend(slide_window(image, x_start_stop=[image.shape[1]-480, None], y_start_stop=[380,700], \n",
    "                        xy_window=(160, 160), xy_overlap=(0.8, 0.8)))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    hot_windows = search_windows(image, windows, clf, X_scaler,model, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)                       \n",
    "    \n",
    "    window_img = draw_boxes(draw_image, hot_windows, color=(0, 0, 255), thick=6)                    \n",
    "\n",
    "    \n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat,hot_windows)\n",
    "\n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat,1)\n",
    "\n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    draw_img = draw_labeled_bboxes(org_image, labels)\n",
    "\n",
    "\n",
    "    \n",
    "    return draw_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video deep_processed.mp4\n",
      "[MoviePy] Writing video deep_processed.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [1:07:46<00:03,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: deep_processed.mp4 \n",
      "\n",
      "CPU times: user 1h 10min 42s, sys: 1min 49s, total: 1h 12min 32s\n",
      "Wall time: 1h 7min 47s\n"
     ]
    }
   ],
   "source": [
    "#cell block 3\n",
    "# Process video\n",
    "\n",
    "white_output = 'deep_processed.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "#clip1=clip1.subclip(15,17)\n",
    "white_clip = clip1.fl_image(video_process_lines) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
