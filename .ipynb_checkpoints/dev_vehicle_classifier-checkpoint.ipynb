{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Training\n",
    "This file contains several tested classifiers for classifying vehicle vs non-vehcile images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cell block 1\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from prod_feature_extraction import *\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cell block 2\n",
    "# Read in cars and notcars, extract features, normalize, shuffle data and split in\n",
    "#to training and test set\n",
    "\n",
    "cars = glob.glob('vehicles/**/*.png')\n",
    "notcars = glob.glob('non-vehicles/**/*.png')\n",
    "\n",
    "\n",
    "\n",
    "color_space = 'YUV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "hog_color_space=\"HSV\"\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (24, 24) # Spatial binning dimensions\n",
    "hist_bins = 20    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off YUV\n",
    "hist_feat = True # Histogram features on or off HSV\n",
    "hog_feat = True # HOG features on or off\n",
    "\n",
    "\n",
    "car_features = extract_features(cars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat,hog_color_space=hog_color_space)\n",
    "notcar_features = extract_features(notcars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat,hog_color_space=hog_color_space)\n",
    "\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = 50\n",
    "scaled_X, y = shuffle(scaled_X, y, random_state=rand_state)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: 9 orientations 8 pixels per cell and 2 cells per block\n",
      "Feature vector length: 7080\n",
      "22.91 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9885\n"
     ]
    }
   ],
   "source": [
    "#cell block 3\n",
    "#train a linearSVC\n",
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC(C=0.01)\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "#store classifier and scaler\n",
    "classifier_dict={\"scaler\":X_scaler,'classifier':svc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14208, 7080)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14208, 2946)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cell block 4\n",
    "#select most relevant features from trained model\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "model = SelectFromModel(svc, prefit=True)\n",
    "X_new = model.transform(X_train)\n",
    "print(X_train.shape)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: 9 orientations 8 pixels per cell and 2 cells per block\n",
      "Feature vector length: 2946\n",
      "2.68 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9879\n"
     ]
    }
   ],
   "source": [
    "#cell block 5\n",
    "#retrain model is selected features\n",
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_new[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC(C=1000)\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_new, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(model.transform(X_test), y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "#save classifier, feature selection and scaler\n",
    "classifier_dict={\"scaler\":X_scaler,'classifier':svc, 'feature_select':model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cell block 6\n",
    "#dump classifier, scaler and feature selector to pickle\n",
    "import pickle\n",
    "\n",
    "with open('linearsvc_vehicle_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(classifier_dict, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1000.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    }
   ],
   "source": [
    "#cell block 7\n",
    "#test several SVM parameters\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid={\n",
    "    'C':[1e3,5e3,1e4,5e4,1e5,1e2,5e2,1.0],\n",
    "    'gamma':[0.0001,0.0005,0.001,0.005,0.01,0.1],\n",
    "    'kernel':['linear','poly','rbf']\n",
    "}\n",
    "grid=GridSearchCV(LinearSVC(),param_grid)\n",
    "grid.fit(X_train,y_train)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-864c1cc99b3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Seconds to train SVC...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Check the score of the SVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test Accuracy of SVC = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't2' is not defined"
     ]
    }
   ],
   "source": [
    "#cell block 8\n",
    "#test decision tree\n",
    "from sklearn import tree\n",
    "tree = tree.DecisionTreeClassifier(min_samples_split=1000)\n",
    "tree.fit(X_train, y_train)\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(tree.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "model2 = SelectFromModel(svc, prefit=True)\n",
    "X_new = model2.transform(X_train)\n",
    "print(X_train.shape)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "Test Accuracy of SVC =  0.9747\n"
     ]
    }
   ],
   "source": [
    "#cell block 9\n",
    "#load saved classifier, scaler and feature selector\n",
    "#test the pickle file worked properly\n",
    "with open('linearsvc_vehicle_classifier.pkl', 'rb') as f:\n",
    "    classifier_dict = pickle.load(f)\n",
    "test_images = glob.glob('test_images/*.jpg')\n",
    "clf=classifier_dict[\"classifier\"]\n",
    "print(clf)\n",
    "X_scaler = classifier_dict[\"scaler\"]\n",
    "print('Test Accuracy of SVC = ', round(clf.score(X_test, y_test), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cell block 10\n",
    "#load data for deep learning classifier\n",
    "cars = glob.glob('vehicles/**/*.png')\n",
    "notcars = glob.glob('non-vehicles/**/*.png')\n",
    "car_features = extract_features(cars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat,hog_color_space=hog_color_space)\n",
    "notcar_features = extract_features(notcars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat,hog_color_space=hog_color_space)\n",
    "\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features))*2, np.zeros(len(notcar_features))))\n",
    "\n",
    "#create one hot labels\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(np.array(y,dtype=np.int32()))\n",
    "y_one_hot=lb.fit_transform(np.array(y,dtype=np.int32()))\n",
    "y_one_hot=np.hstack(( 1 - y_one_hot,y_one_hot))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = 50\n",
    "scaled_X, y_one_hot = shuffle(model.transform(scaled_X), y_one_hot, random_state=rand_state)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y_one_hot, test_size=0.2, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cell block 11\n",
    "#build keras network\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "model = Sequential()\n",
    "# TODO: Build a Multi-layer feedforward neural network with Keras here.\n",
    "# Create the Sequential model\n",
    "\n",
    "# 2nd Layer - Add a fully connected layer\n",
    "model.add(Dense(200,batch_input_shape=(None, 2946)))\n",
    "\n",
    "# 3rd Layer - Add a ReLU activation layer\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(100))\n",
    "\n",
    "# 3rd Layer - Add a ReLU activation layer\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# 4th Layer - Add a fully connected layer\n",
    "model.add(Dense(80))\n",
    "\n",
    "# 3rd Layer - Add a ReLU activation layer\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# 4th Layer - Add a fully connected layer\n",
    "model.add(Dense(60))\n",
    "\n",
    "# 3rd Layer - Add a ReLU activation layer\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# 4th Layer - Add a fully connected layer\n",
    "model.add(Dense(30))\n",
    "\n",
    "# 3rd Layer - Add a ReLU activation layer\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# 4th Layer - Add a fully connected layer\n",
    "model.add(Dense(15))\n",
    "\n",
    "# 3rd Layer - Add a ReLU activation layer\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# 4th Layer - Add a fully connected layer\n",
    "model.add(Dense(8))\n",
    "\n",
    "# 3rd Layer - Add a ReLU activation layer\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 4th Layer - Add a fully connected layer\n",
    "model.add(Dense(2))\n",
    "\n",
    "# 5th Layer - Add a ReLU activation layer\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11366 samples, validate on 2842 samples\n",
      "Epoch 1/5\n",
      "11366/11366 [==============================] - 5s - loss: 0.0276 - acc: 0.9938 - val_loss: 0.0418 - val_acc: 0.9944\n",
      "Epoch 2/5\n",
      "11366/11366 [==============================] - 3s - loss: 0.0226 - acc: 0.9938 - val_loss: 0.0181 - val_acc: 0.9951\n",
      "Epoch 3/5\n",
      "11366/11366 [==============================] - 4s - loss: 0.0163 - acc: 0.9962 - val_loss: 0.0264 - val_acc: 0.9940\n",
      "Epoch 4/5\n",
      "11366/11366 [==============================] - 3s - loss: 0.0182 - acc: 0.9959 - val_loss: 0.0339 - val_acc: 0.9954\n",
      "Epoch 5/5\n",
      "11366/11366 [==============================] - 3s - loss: 0.0197 - acc: 0.9947 - val_loss: 0.0176 - val_acc: 0.9961\n"
     ]
    }
   ],
   "source": [
    "#cell block 12\n",
    "#train keras network using an adam optimizer\n",
    "model.compile('Adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size=128, nb_epoch=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3552/3552 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.066367474743118729, 0.98930180180180183]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cell block 13\n",
    "#test rained model on test set\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cell block 14\n",
    "#save keras model to file\n",
    "model.save(\"model_alt.h5\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
